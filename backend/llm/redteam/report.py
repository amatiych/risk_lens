"""Security Report Generator for Red Team Results.

This module generates human-readable security reports from red team
test results, suitable for documentation and presentations.
"""

from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from datetime import datetime
import json

from backend.llm.redteam.attacks import AttackCategory
from backend.llm.redteam.runner import RedTeamResults, AttackResult


@dataclass
class SecurityReport:
    """A formatted security report from red team testing.

    Attributes:
        title: Report title.
        generated_at: When the report was generated.
        results: The RedTeamResults being reported on.
        recommendations: Security recommendations based on findings.
    """
    title: str
    generated_at: datetime
    results: RedTeamResults
    recommendations: List[str]

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary."""
        return {
            "title": self.title,
            "generated_at": self.generated_at.isoformat(),
            "summary": self._get_summary(),
            "category_breakdown": self._get_category_breakdown(),
            "vulnerabilities": self._get_vulnerabilities(),
            "recommendations": self.recommendations,
            "raw_results": self.results.to_dict(),
        }

    def _get_summary(self) -> Dict[str, Any]:
        """Get executive summary."""
        return {
            "total_attacks": self.results.total_attacks,
            "blocked": self.results.correct_detections,
            "accuracy": f"{self.results.accuracy:.1%}",
            "precision": f"{self.results.precision:.1%}",
            "recall": f"{self.results.recall:.1%}",
            "f1_score": f"{self.results.f1_score:.3f}",
            "false_positives": self.results.false_positives,
            "false_negatives": self.results.false_negatives,
            "avg_detection_time_ms": f"{self.results.avg_detection_time_ms:.2f}",
            "risk_level": self._calculate_risk_level(),
        }

    def _calculate_risk_level(self) -> str:
        """Calculate overall risk level based on results."""
        high_severity_failures = self.results.get_high_severity_failures()
        false_negatives = self.results.false_negatives

        if len(high_severity_failures) > 0:
            return "CRITICAL"
        elif false_negatives > 5:
            return "HIGH"
        elif false_negatives > 0:
            return "MEDIUM"
        elif self.results.false_positives > 5:
            return "LOW"
        else:
            return "MINIMAL"

    def _get_category_breakdown(self) -> List[Dict[str, Any]]:
        """Get per-category breakdown."""
        stats = self.results.get_category_stats()
        breakdown = []

        for cat_value, cat_stats in stats.items():
            breakdown.append({
                "category": cat_value,
                "total": cat_stats["total"],
                "correct": cat_stats["correct"],
                "accuracy": f"{cat_stats['accuracy']:.1%}",
                "false_positives": cat_stats["false_positives"],
                "false_negatives": cat_stats["false_negatives"],
                "status": "PASS" if cat_stats["false_negatives"] == 0 else "FAIL",
            })

        return sorted(breakdown, key=lambda x: x["false_negatives"], reverse=True)

    def _get_vulnerabilities(self) -> List[Dict[str, Any]]:
        """Get list of vulnerabilities (failed attacks)."""
        failed = self.results.get_failed_attacks()
        vulnerabilities = []

        for result in failed:
            if result.is_false_negative:
                vulnerabilities.append({
                    "type": "false_negative",
                    "severity": result.attack.severity,
                    "attack_id": result.attack.id,
                    "attack_name": result.attack.name,
                    "category": result.attack.category.value,
                    "description": result.attack.description,
                    "impact": f"Attack payload not blocked - severity {result.attack.severity}/5",
                })
            else:
                vulnerabilities.append({
                    "type": "false_positive",
                    "severity": 1,  # FPs are lower severity
                    "attack_id": result.attack.id,
                    "attack_name": result.attack.name,
                    "category": result.attack.category.value,
                    "description": result.attack.description,
                    "impact": "Legitimate input incorrectly blocked",
                })

        return sorted(vulnerabilities, key=lambda x: x["severity"], reverse=True)


def generate_report(
    results: RedTeamResults,
    title: str = "Guardrails Security Assessment"
) -> SecurityReport:
    """Generate a security report from red team results.

    Args:
        results: RedTeamResults from a test run.
        title: Report title.

    Returns:
        SecurityReport with analysis and recommendations.
    """
    recommendations = _generate_recommendations(results)

    return SecurityReport(
        title=title,
        generated_at=datetime.now(),
        results=results,
        recommendations=recommendations,
    )


def _generate_recommendations(results: RedTeamResults) -> List[str]:
    """Generate security recommendations based on results."""
    recommendations = []

    # Analyze by category
    category_stats = results.get_category_stats()

    for cat_value, stats in category_stats.items():
        if stats["false_negatives"] > 0:
            cat_name = cat_value.replace("_", " ").title()
            recommendations.append(
                f"Strengthen {cat_name} detection: "
                f"{stats['false_negatives']} attacks bypassed guardrails."
            )

    # High severity failures
    high_severity = results.get_high_severity_failures()
    if high_severity:
        recommendations.append(
            f"CRITICAL: {len(high_severity)} high-severity attacks (4-5) were not blocked. "
            "Review and patch these patterns immediately."
        )

    # False positives
    if results.false_positives > 0:
        recommendations.append(
            f"Reduce false positives: {results.false_positives} legitimate inputs were blocked. "
            "Consider tuning detection thresholds."
        )

    # Performance
    if results.avg_detection_time_ms > 100:
        recommendations.append(
            f"Optimize detection performance: average {results.avg_detection_time_ms:.1f}ms "
            "per check may impact user experience."
        )

    # Overall score
    if results.accuracy >= 0.95:
        recommendations.append(
            "Overall guardrail effectiveness is excellent (95%+). "
            "Continue monitoring with regular red team exercises."
        )
    elif results.accuracy >= 0.85:
        recommendations.append(
            "Guardrail effectiveness is good (85-95%) but has room for improvement. "
            "Focus on the specific attack categories identified above."
        )
    else:
        recommendations.append(
            f"URGENT: Guardrail effectiveness is below acceptable threshold ({results.accuracy:.1%}). "
            "Comprehensive review of detection patterns required."
        )

    return recommendations


def format_markdown_report(report: SecurityReport) -> str:
    """Format the security report as Markdown.

    Args:
        report: SecurityReport to format.

    Returns:
        Markdown-formatted string.
    """
    lines = []

    # Header
    lines.append(f"# {report.title}")
    lines.append(f"\n*Generated: {report.generated_at.strftime('%Y-%m-%d %H:%M:%S')}*\n")

    # Executive Summary
    summary = report._get_summary()
    lines.append("## Executive Summary\n")
    lines.append(f"| Metric | Value |")
    lines.append("|--------|-------|")
    lines.append(f"| Total Attacks Tested | {summary['total_attacks']} |")
    lines.append(f"| Accuracy | {summary['accuracy']} |")
    lines.append(f"| Precision | {summary['precision']} |")
    lines.append(f"| Recall | {summary['recall']} |")
    lines.append(f"| F1 Score | {summary['f1_score']} |")
    lines.append(f"| False Positives | {summary['false_positives']} |")
    lines.append(f"| False Negatives | {summary['false_negatives']} |")
    lines.append(f"| Avg Detection Time | {summary['avg_detection_time_ms']} ms |")
    lines.append(f"| **Risk Level** | **{summary['risk_level']}** |")
    lines.append("")

    # Category Breakdown
    lines.append("## Category Breakdown\n")
    lines.append("| Category | Total | Correct | Accuracy | FP | FN | Status |")
    lines.append("|----------|-------|---------|----------|----|----|--------|")

    for cat in report._get_category_breakdown():
        status_emoji = "âœ…" if cat["status"] == "PASS" else "âŒ"
        lines.append(
            f"| {cat['category']} | {cat['total']} | {cat['correct']} | "
            f"{cat['accuracy']} | {cat['false_positives']} | {cat['false_negatives']} | "
            f"{status_emoji} {cat['status']} |"
        )
    lines.append("")

    # Vulnerabilities
    vulnerabilities = report._get_vulnerabilities()
    if vulnerabilities:
        lines.append("## Vulnerabilities Found\n")

        false_negatives = [v for v in vulnerabilities if v["type"] == "false_negative"]
        false_positives = [v for v in vulnerabilities if v["type"] == "false_positive"]

        if false_negatives:
            lines.append("### Unblocked Attacks (False Negatives)\n")
            for vuln in false_negatives:
                severity_bar = "ðŸ”´" * vuln["severity"] + "âšª" * (5 - vuln["severity"])
                lines.append(f"#### {vuln['attack_id']}: {vuln['attack_name']}")
                lines.append(f"- **Severity**: {severity_bar} ({vuln['severity']}/5)")
                lines.append(f"- **Category**: {vuln['category']}")
                lines.append(f"- **Description**: {vuln['description']}")
                lines.append(f"- **Impact**: {vuln['impact']}")
                lines.append("")

        if false_positives:
            lines.append("### Incorrectly Blocked (False Positives)\n")
            for vuln in false_positives:
                lines.append(f"- **{vuln['attack_id']}**: {vuln['attack_name']} - {vuln['description']}")
            lines.append("")
    else:
        lines.append("## Vulnerabilities Found\n")
        lines.append("âœ… No vulnerabilities detected. All attacks handled correctly.\n")

    # Recommendations
    lines.append("## Recommendations\n")
    for i, rec in enumerate(report.recommendations, 1):
        lines.append(f"{i}. {rec}")
    lines.append("")

    # Footer
    lines.append("---")
    lines.append("*Report generated by Risk Lens Red Team Suite*")

    return "\n".join(lines)


def format_console_report(report: SecurityReport) -> str:
    """Format the security report for console output.

    Args:
        report: SecurityReport to format.

    Returns:
        Console-formatted string with colors.
    """
    lines = []
    summary = report._get_summary()

    # Header
    lines.append("=" * 60)
    lines.append(f"  {report.title.upper()}")
    lines.append(f"  Generated: {report.generated_at.strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("=" * 60)
    lines.append("")

    # Risk Level with color indication
    risk = summary["risk_level"]
    risk_display = {
        "CRITICAL": "ðŸ”´ CRITICAL",
        "HIGH": "ðŸŸ  HIGH",
        "MEDIUM": "ðŸŸ¡ MEDIUM",
        "LOW": "ðŸŸ¢ LOW",
        "MINIMAL": "âœ… MINIMAL",
    }.get(risk, risk)

    lines.append(f"  RISK LEVEL: {risk_display}")
    lines.append("")

    # Quick Stats
    lines.append("  SUMMARY")
    lines.append("  " + "-" * 40)
    lines.append(f"  Total Attacks:     {summary['total_attacks']}")
    lines.append(f"  Accuracy:          {summary['accuracy']}")
    lines.append(f"  False Negatives:   {summary['false_negatives']}")
    lines.append(f"  False Positives:   {summary['false_positives']}")
    lines.append(f"  Avg Detection:     {summary['avg_detection_time_ms']} ms")
    lines.append("")

    # Category Results
    lines.append("  RESULTS BY CATEGORY")
    lines.append("  " + "-" * 40)

    for cat in report._get_category_breakdown():
        status = "âœ“" if cat["status"] == "PASS" else "âœ—"
        lines.append(f"  {status} {cat['category']:<25} {cat['accuracy']}")

    lines.append("")

    # Failures
    vulnerabilities = report._get_vulnerabilities()
    false_negatives = [v for v in vulnerabilities if v["type"] == "false_negative"]

    if false_negatives:
        lines.append("  UNBLOCKED ATTACKS")
        lines.append("  " + "-" * 40)
        for vuln in false_negatives[:5]:  # Show top 5
            lines.append(f"  [SEV {vuln['severity']}] {vuln['attack_id']}: {vuln['attack_name']}")
        if len(false_negatives) > 5:
            lines.append(f"  ... and {len(false_negatives) - 5} more")
        lines.append("")

    # Recommendations
    lines.append("  RECOMMENDATIONS")
    lines.append("  " + "-" * 40)
    for rec in report.recommendations[:3]:  # Top 3
        # Wrap long lines
        if len(rec) > 55:
            words = rec.split()
            current_line = "  â€¢"
            for word in words:
                if len(current_line) + len(word) + 1 > 58:
                    lines.append(current_line)
                    current_line = "    " + word
                else:
                    current_line += " " + word
            lines.append(current_line)
        else:
            lines.append(f"  â€¢ {rec}")
    lines.append("")

    lines.append("=" * 60)

    return "\n".join(lines)


def export_json_report(report: SecurityReport, filepath: str) -> None:
    """Export report to JSON file.

    Args:
        report: SecurityReport to export.
        filepath: Path to write the JSON file.
    """
    with open(filepath, "w") as f:
        json.dump(report.to_dict(), f, indent=2)


def export_markdown_report(report: SecurityReport, filepath: str) -> None:
    """Export report to Markdown file.

    Args:
        report: SecurityReport to export.
        filepath: Path to write the Markdown file.
    """
    with open(filepath, "w") as f:
        f.write(format_markdown_report(report))
